"""
VERSI√ìN MODIFICADA DE IMPUTACION_CORRELACION.PY QUE GENERA DICCIONARIOS DE MODELOS

Esta versi√≥n extiende la funci√≥n original para generar y retornar diccionarios
completos de modelos que pueden ser usados por el sistema de an√°lisis visual.
"""

import pandas as pd
import numpy as np
from itertools import combinations
from collections import defaultdict
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.model_selection import LeaveOneOut
from sklearn.metrics import mean_absolute_percentage_error, r2_score

# Importar funciones originales
from .imputacion_correlacion import (
    is_missing, cargar_y_validar_datos, penalizacion_por_k,
    seleccionar_predictores_validos, generar_combinaciones, entrenar_modelo,
    imputar_valores_celda, imputaciones_correlacion, filtrar_mejores_modelos
)

# Importar funci√≥n de validaci√≥n LOOCV
try:
    from .imputacion_correlacion import validar_con_loocv
except ImportError:
    print("‚ö†Ô∏è Funci√≥n validar_con_loocv no encontrada, se implementar√° localmente")

def imputaciones_correlacion_con_diccionarios(df, path: str | None = None):
    """
    Versi√≥n extendida de imputaciones_correlacion que TAMBI√âN genera diccionarios
    de modelos para ser usados por el sistema de an√°lisis visual.
    
    Returns:
        df_resultado: DataFrame con valores imputados
        reporte: Lista de reportes de imputaci√≥n  
        diccionarios_modelos: Dict con todos los modelos entrenados por celda
    """
    if isinstance(df, str):
        df = pd.read_excel(df)
    df = df.rename(columns=lambda c: str(c).strip())
    df.replace("", np.nan, inplace=True)
    
    df_original = df
    df_resultado = df_original.copy()
    reporte = []
    diccionarios_modelos = {}  # ‚Üê NUEVO: Almacenar modelos por celda
    
    print("üîß Ejecutando imputaci√≥n por correlaci√≥n CON generaci√≥n de diccionarios...")
    
    for objetivo in [c for c in df_original.columns if df_original[c].isna().any()]:
        faltantes = df_original[df_original[objetivo].isna()].index
        
        for idx in faltantes:
            clave_celda = f"aeronave_{idx}_parametro_{objetivo}"
            print(f"  üìä Procesando: {clave_celda}")
            
            # Seleccionar predictores v√°lidos
            df_filtrado, familia_usada, filtro_aplicado = seleccionar_predictores_validos(
                df_original, objetivo, idx
            )
            
            if df_filtrado.empty:
                print(f"    ‚ùå Sin datos v√°lidos para {clave_celda}")
                continue
            
            # Excluir primera columna y objetivo
            predictores = [
                col for col in df_filtrado.columns 
                if col != df_filtrado.columns[0] and col != objetivo
            ]
            
            if not predictores:
                print(f"    ‚ùå Sin predictores v√°lidos para {clave_celda}")
                # Agregar entrada vac√≠a al diccionario
                diccionarios_modelos[clave_celda] = {
                    "mejor_modelo": None,
                    "todos_los_modelos": [],
                    "df_filtrado": df_filtrado,
                    "predictores": [],
                    "familia_usada": familia_usada,
                    "filtro_aplicado": filtro_aplicado,
                    "error": "Sin predictores v√°lidos"
                }
                
                reporte.append({
                    "Aeronave": idx,
                    "Par√°metro": objetivo,
                    "Valor imputado": "NAN",
                    "Confianza": 0,
                    "Tipo Modelo": "N/A",
                    "Predictores": "N/A",
                    "k": 0,
                    "Penalizacion_k": 0,
                    "Corr": 0,
                    "Familia": familia_usada,
                    "M√©todo predictivo": "Correlacion",
                    "Advertencia": "No se pudo imputar por falta de par√°metros v√°lidos."
                })
                continue
            
            try:
                # Generar combinaciones y entrenar TODOS los modelos
                combos = generar_combinaciones(predictores)
                todos_los_modelos = []
                
                print(f"    üîÑ Entrenando {len(combos)} combinaciones...")
                
                for combo in combos:
                    # Modelos normales
                    for poly in [False, True]:
                        try:
                            modelo = entrenar_modelo(df_filtrado, objetivo, combo, poly, idx)
                            if modelo:
                                todos_los_modelos.append(modelo)
                        except Exception as e:
                            print(f"      ‚ö†Ô∏è Error modelo {combo}, poly={poly}: {e}")
                    
                    # Modelos especiales (solo para 1 predictor)
                    if len(combo) == 1:
                        for modelo_tipo in ["log", "power", "exp"]:
                            try:
                                modelo = entrenar_modelo(df_filtrado, objetivo, combo, False, idx, modelo_tipo)
                                if modelo:
                                    todos_los_modelos.append(modelo)
                            except Exception as e:
                                print(f"      ‚ö†Ô∏è Error modelo {combo}, tipo={modelo_tipo}: {e}")
                
                if not todos_los_modelos:
                    print(f"    ‚ùå No se pudo entrenar ning√∫n modelo para {clave_celda}")
                    diccionarios_modelos[clave_celda] = {
                        "mejor_modelo": None,
                        "todos_los_modelos": [],
                        "df_filtrado": df_filtrado,
                        "predictores": predictores,
                        "familia_usada": familia_usada,
                        "filtro_aplicado": filtro_aplicado,
                        "error": "No se pudo entrenar ning√∫n modelo"
                    }
                    continue
                  # Evaluar todos los modelos usando la misma l√≥gica que el original
                # Solo pasar a LOOCV los modelos con MAPE <= 7.5% y R2 >= 0.6
                validos = [m for m in todos_los_modelos 
                          if m is not None and not m.get("descartado", False) 
                          and m.get("mape", 100) <= 7.5 and m.get("r2", 0) >= 0.6]
                
                if not validos:
                    print(f"    ‚ùå Ning√∫n modelo v√°lido para {clave_celda}")
                    diccionarios_modelos[clave_celda] = {
                        "mejor_modelo": None,
                        "todos_los_modelos": todos_los_modelos,
                        "df_filtrado": df_filtrado,
                        "predictores": predictores,
                        "familia_usada": familia_usada,
                        "filtro_aplicado": filtro_aplicado,
                        "error": "Ning√∫n modelo pas√≥ validaci√≥n inicial"
                    }
                    continue
                
                # Validar con LOOCV y calcular confianza promedio
                try:
                    from .imputacion_correlacion import validar_con_loocv
                    for m in validos:
                        m.update(validar_con_loocv(df_filtrado, objetivo, m))
                        m["Confianza_promedio"] = (m["Confianza"] + m["Confianza_LOOCV"]) / 2
                except ImportError:
                    # Fallback: usar solo confianza inicial
                    for m in validos:
                        m["Confianza_promedio"] = m.get("Confianza", 0)
                
                # Filtrar modelos robustos por LOOCV (misma l√≥gica que original)
                robustos = [m for m in validos 
                           if m.get("MAPE_LOOCV", 100) <= 15 and m.get("R2_LOOCV", 0) >= 0.6]
                
                if robustos:
                    mejor_modelo = max(robustos, key=lambda x: x["Confianza_promedio"])
                    warning_text = "Modelo robusto"
                else:
                    mejor_modelo = max(validos, key=lambda x: x["Confianza_promedio"])
                    warning_text = "Modelo no robusto"
                
                if not filtro_aplicado:
                    warning_text += "; modelo sin filtrado por familia"
                
                mejor_modelo["warning"] = warning_text
                mejor_modelo["Familia"] = familia_usada
                
                if not mejor_modelo:
                    print(f"    ‚ùå No se encontr√≥ mejor modelo para {clave_celda}")
                    diccionarios_modelos[clave_celda] = {
                        "mejor_modelo": None,
                        "todos_los_modelos": todos_los_modelos,
                        "df_filtrado": df_filtrado,
                        "predictores": predictores,
                        "familia_usada": familia_usada,
                        "filtro_aplicado": filtro_aplicado,
                        "error": "No se pudo evaluar modelos"
                    }
                    continue
                
                # ‚úÖ GUARDAR DICCIONARIO COMPLETO
                diccionarios_modelos[clave_celda] = {
                    "mejor_modelo": mejor_modelo,
                    "todos_los_modelos": todos_los_modelos,
                    "df_filtrado": df_filtrado,
                    "predictores": predictores,
                    "familia_usada": familia_usada,
                    "filtro_aplicado": filtro_aplicado
                }
                
                print(f"    ‚úÖ Mejor modelo: {mejor_modelo['tipo']} - R¬≤={mejor_modelo.get('r2', 0):.3f}")
                
                # Imputar valor usando el mejor modelo
                df_resultado, imputacion = imputar_valores_celda(
                    df_resultado, df_filtrado, objetivo, mejor_modelo, idx
                )
                
                imputacion["Familia"] = familia_usada
                reporte.append(imputacion)
                
            except Exception as e:
                print(f"    ‚ùå Error procesando {clave_celda}: {e}")
                diccionarios_modelos[clave_celda] = {
                    "mejor_modelo": None,
                    "todos_los_modelos": [],
                    "df_filtrado": df_filtrado,
                    "predictores": predictores,
                    "familia_usada": familia_usada,
                    "filtro_aplicado": filtro_aplicado,
                    "error": str(e)
                }
    
    print(f"‚úÖ Diccionarios generados para {len(diccionarios_modelos)} celdas")
    
    return df_resultado, reporte, diccionarios_modelos


def filtrar_solo_correlacion_desde_diccionarios(diccionarios_modelos: dict, detalles_para_excel: list) -> dict:
    """
    Filtra los diccionarios para quedarse solo con las imputaciones por correlaci√≥n,
    excluyendo similitud y promedios ponderados.
    
    Args:
        diccionarios_modelos: Diccionarios completos de modelos
        detalles_para_excel: Lista de detalles que van al Excel final
        
    Returns:
        dict: Diccionarios filtrados solo con correlaci√≥n
    """
    diccionarios_correlacion = {}
    
    # Extraer claves de celdas que fueron imputadas por correlaci√≥n
    celdas_correlacion = set()
    for detalle in detalles_para_excel:
        if detalle.get("M√©todo predictivo") == "Correlacion":
            aeronave = detalle.get("Aeronave")
            parametro = detalle.get("Par√°metro")
            clave = f"aeronave_{aeronave}_parametro_{parametro}"
            celdas_correlacion.add(clave)
    
    # Filtrar diccionarios
    for clave, datos in diccionarios_modelos.items():
        if clave in celdas_correlacion:
            diccionarios_correlacion[clave] = datos
            print(f"  ‚úÖ Incluido: {clave}")
        else:
            print(f"  ‚ùå Excluido (no es correlaci√≥n): {clave}")
    
    print(f"üìä Filtrados: {len(diccionarios_correlacion)}/{len(diccionarios_modelos)} celdas")
    return diccionarios_correlacion
