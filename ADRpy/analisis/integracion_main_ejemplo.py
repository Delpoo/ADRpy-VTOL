"""
EJEMPLO DE INTEGRACI√ìN DEL SISTEMA DE AN√ÅLISIS VISUAL CON MAIN.PY

Este archivo muestra c√≥mo integrar el sistema de an√°lisis visual din√°mico
con el flujo principal de imputaci√≥n por correlaci√≥n.
"""

# ================================================================================
# MODIFICACIONES NECESARIAS EN MAIN.PY
# ================================================================================

def main_con_analisis_visual():
    """
    Versi√≥n modificada de main() que incluye el an√°lisis visual.
    Integra el notebook de an√°lisis al final del proceso de imputaci√≥n.
    """
    
    print("üöÄ SISTEMA PRINCIPAL DE IMPUTACI√ìN CON AN√ÅLISIS VISUAL")
    print("=" * 55)
    
    # 1. CARGA DE DATOS (como en main.py original)
    df = cargar_y_validar_datos("ruta/a/datos.xlsx")
    df_original = df.copy()  # ‚ö†Ô∏è IMPORTANTE: Guardar copia original
    
    # 2. EJECUTAR IMPUTACI√ìN (como en main.py original)
    print("üîÑ Ejecutando imputaci√≥n por correlaci√≥n...")
    df_resultado, reporte = imputaciones_correlacion(df)
    
    # 3. RECOPILAR DICCIONARIOS DE MODELOS (NUEVO)
    print("üìä Recopilando modelos para an√°lisis visual...")
    diccionarios_modelos_globales = recopilar_diccionarios_modelos(df_original)
    
    # 4. AN√ÅLISIS VISUAL DIN√ÅMICO (NUEVO)
    print("\nüéØ INICIANDO AN√ÅLISIS VISUAL DIN√ÅMICO")
    print("=" * 40)
    
    try:
        # Importar el sistema de an√°lisis
        from analisis_modelos_imputacion import ejecutar_analisis_visual
        
        # Ejecutar an√°lisis visual
        interfaz = ejecutar_analisis_visual(
            df_original=df_original,
            diccionarios_modelos=diccionarios_modelos_globales,
            df_resultado=df_resultado
        )
        
        if interfaz:
            print("‚úÖ An√°lisis visual iniciado exitosamente")
            print("üéÆ Use la interfaz interactiva para explorar los modelos")
        else:
            print("‚ùå Error iniciando an√°lisis visual")
            
    except Exception as e:
        print(f"‚ùå Error en an√°lisis visual: {e}")
        print("üí° Continuando con el flujo normal...")
    
    # 5. CONTINUAR CON EL RESTO DEL MAIN.PY
    # Exportaci√≥n, reportes, etc.
    
    return df_resultado, reporte

def recopilar_diccionarios_modelos(df_original):
    """
    Funci√≥n para recopilar todos los diccionarios de modelos durante la imputaci√≥n.
    Esta funci√≥n debe modificarse para capturar los modelos durante el proceso.
    """
    
    diccionarios_globales = {}
    
    # Iterar por cada celda con valores faltantes
    for objetivo in [c for c in df_original.columns if df_original[c].isna().any()]:
        faltantes = df_original[df_original[objetivo].isna()].index
        
        for idx in faltantes:
            clave_celda = f"aeronave_{idx}_parametro_{objetivo}"
            
            # Ejecutar la misma l√≥gica que en imputaciones_correlacion
            # pero guardando TODOS los modelos, no solo el mejor
            
            try:
                # Preparar datos (misma l√≥gica que imputacion_correlacion.py)
                df_filtrado, familia_usada, filtro_aplicado = seleccionar_predictores_validos(
                    df_original, objetivo, idx
                )
                
                if df_filtrado.empty:
                    continue
                
                predictores = [col for col in df_filtrado.columns 
                              if col != df_filtrado.columns[0] and col != objetivo]
                
                if not predictores:
                    continue
                
                # Entrenar TODOS los modelos (no solo el mejor)
                todos_los_modelos = entrenar_todos_los_modelos_para_analisis(
                    df_filtrado, objetivo, predictores, idx
                )
                
                # Seleccionar el mejor modelo
                mejor_modelo = seleccionar_mejor_modelo(todos_los_modelos)
                
                # Guardar informaci√≥n completa
                diccionarios_globales[clave_celda] = {
                    "mejor_modelo": mejor_modelo,
                    "todos_los_modelos": todos_los_modelos,
                    "df_filtrado": df_filtrado,
                    "predictores": predictores,
                    "familia_usada": familia_usada,
                    "filtro_aplicado": filtro_aplicado
                }
                
            except Exception as e:
                print(f"‚ö†Ô∏è Error procesando {clave_celda}: {e}")
                continue
    
    return diccionarios_globales

def entrenar_todos_los_modelos_para_analisis(df_filtrado, objetivo, predictores, idx):
    """
    Funci√≥n para entrenar TODOS los modelos posibles para una celda.
    Esta funci√≥n es similar a la l√≥gica en AnalizadorModelos._entrenar_todos_los_modelos
    pero adaptada para usar durante el flujo principal.
    """
    
    modelos = []
    
    # Generar todas las combinaciones de predictores
    for combo in generar_combinaciones(predictores):
        # Modelos lineales y polin√≥micos
        for poly in (False, True):
            modelo = entrenar_modelo(df_filtrado, objetivo, combo, poly, idx)
            if modelo and not modelo.get("descartado", False):
                # Agregar validaci√≥n LOOCV
                modelo.update(validar_con_loocv(df_filtrado, objetivo, modelo))
                modelo["Confianza_promedio"] = (
                    modelo["Confianza"] + modelo.get("Confianza_LOOCV", 0)
                ) / 2
                modelos.append(modelo)
        
        # Modelos especiales solo para 1 predictor
        if len(combo) == 1:
            for tipo_especial in ["log", "potencia", "exp"]:
                modelo = entrenar_modelo(
                    df_filtrado, objetivo, combo, False, idx, 
                    modelo_extra=tipo_especial
                )
                if modelo and not modelo.get("descartado", False):
                    # Agregar validaci√≥n LOOCV
                    modelo.update(validar_con_loocv(df_filtrado, objetivo, modelo))
                    modelo["Confianza_promedio"] = (
                        modelo["Confianza"] + modelo.get("Confianza_LOOCV", 0)
                    ) / 2
                    modelos.append(modelo)
    
    return modelos

def seleccionar_mejor_modelo(modelos):
    """
    Seleccionar el mejor modelo usando los mismos criterios que imputacion_correlacion.py
    """
    if not modelos:
        return None
    
    # Filtrar modelos v√°lidos
    validos = [m for m in modelos if m["mape"] <= 7.5 and m["r2"] >= 0.6]
    
    if not validos:
        return None
    
    # Seleccionar por m√°xima confianza promedio
    mejor = max(validos, key=lambda x: x["Confianza_promedio"])
    return mejor

# ================================================================================
# INSTRUCCIONES DE IMPLEMENTACI√ìN
# ================================================================================

"""
PASOS PARA INTEGRAR EN EL MAIN.PY ACTUAL:

1. MODIFICAR imputaciones_correlacion():
   - Agregar par√°metro 'recopilar_modelos=False'
   - Si es True, guardar todos los modelos en lugar de solo el mejor
   - Retornar diccionarios_modelos adem√°s de df_resultado y reporte

2. MODIFICAR main():
   - Guardar df_original antes de la imputaci√≥n
   - Llamar imputaciones_correlacion con recopilar_modelos=True
   - Despu√©s de la imputaci√≥n, llamar ejecutar_analisis_visual()

3. OPCIONAL - Crear funci√≥n wrapper:
   - main_con_analisis() que incluya todo
   - Mantener main() original para compatibilidad

EJEMPLO DE USO FINAL:

if __name__ == "__main__":
    # Opci√≥n 1: Main tradicional
    # main()
    
    # Opci√≥n 2: Main con an√°lisis visual
    main_con_analisis_visual()
"""

# ================================================================================
# C√ìDIGO DE EJEMPLO PARA TESTING
# ================================================================================

def test_integracion():
    """
    Funci√≥n de prueba para verificar la integraci√≥n.
    """
    print("üß™ TEST DE INTEGRACI√ìN")
    print("=" * 25)
    
    # Simular datos del flujo principal
    import pandas as pd
    import numpy as np
    
    # Crear datos de ejemplo
    df_original = pd.DataFrame({
        'aeronave': [1, 2, 3, 4, 5],
        'parametro_A': [10, 20, np.nan, 40, 50],
        'parametro_B': [100, 200, 300, np.nan, 500],
        'predictor_1': [1, 2, 3, 4, 5],
        'predictor_2': [10, 20, 30, 40, 50]
    })
    
    # Simular diccionarios de modelos
    diccionarios_ejemplo = {
        "aeronave_2_parametro_parametro_A": {
            "mejor_modelo": {
                "tipo": "linear",
                "mape": 5.0,
                "r2": 0.95,
                "Confianza": 0.8,
                "Confianza_LOOCV": 0.75,
                "Confianza_promedio": 0.775,
                "predictores": ["predictor_1"],
                "coeficientes_originales": [2.0],
                "intercepto_original": 5.0
            },
            "todos_los_modelos": [],  # Lista de todos los modelos
            "df_filtrado": df_original,
            "predictores": ["predictor_1", "predictor_2"],
            "familia_usada": "sin filtro",
            "filtro_aplicado": "ninguno"
        }
    }
    
    try:
        # Test de la funci√≥n de integraci√≥n
        interfaz = inicializar_sistema_analisis_desde_main(
            df_original, 
            diccionarios_ejemplo
        )
        
        if interfaz:
            print("‚úÖ Test de integraci√≥n exitoso")
            return True
        else:
            print("‚ùå Test de integraci√≥n fall√≥")
            return False
            
    except Exception as e:
        print(f"‚ùå Error en test: {e}")
        return False

if __name__ == "__main__":
    test_integracion()
